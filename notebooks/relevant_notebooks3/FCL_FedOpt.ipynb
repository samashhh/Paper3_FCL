{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Training Dataset Size: 45000 images\n",
      "Validation Dataset Size: 5000 images\n",
      "Test Dataset Size: 10000 images\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setting up FL with 8 Clients\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "# Set device (GPU or CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Transformations for CIFAR-100\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load CIFAR-100 dataset (train and test)\n",
    "dataset_train = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
    "dataset_test = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Total number of images after reserving 10% for validation (90% for training)\n",
    "num_train_images = int(0.9 * len(dataset_train))  # 45,000 images for training\n",
    "num_val_images = len(dataset_train) - num_train_images  # 5,000 images for validation\n",
    "\n",
    "# Randomly split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset_train, [num_train_images, num_val_images])\n",
    "\n",
    "# Create DataLoaders for training, validation, and test sets\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Output to check the size of the training, validation, and test sets\n",
    "print(f\"Training Dataset Size: {len(train_loader.dataset)} images\")\n",
    "print(f\"Validation Dataset Size: {len(val_loader.dataset)} images\")\n",
    "print(f\"Test Dataset Size: {len(test_loader.dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 Dataset Size: 5625 images\n",
      "Client 2 Dataset Size: 5625 images\n",
      "Client 3 Dataset Size: 5625 images\n",
      "Client 4 Dataset Size: 5625 images\n",
      "Client 5 Dataset Size: 5625 images\n",
      "Client 6 Dataset Size: 5625 images\n",
      "Client 7 Dataset Size: 5625 images\n",
      "Client 8 Dataset Size: 5625 images\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split the training dataset into 8 clients\n",
    "\n",
    "# Each client will get 5625 images\n",
    "client_splits = torch.utils.data.random_split(train_dataset, [5625] * 8)\n",
    "\n",
    "# Verify that each client has 5625 images\n",
    "for i, client_dataset in enumerate(client_splits):\n",
    "    print(f\"Client {i+1} Dataset Size: {len(client_dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 First Batch - Images Shape: torch.Size([256, 3, 224, 224]), Labels Shape: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create DataLoaders for each client\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "\n",
    "# Create a DataLoader for each client\n",
    "client_loaders = [DataLoader(client_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers) for client_dataset in client_splits]\n",
    "\n",
    "# Also create a DataLoader for the validation set\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# Output to verify one batch from Client 1\n",
    "images, labels = next(iter(client_loaders[0]))\n",
    "print(f\"Client 1 First Batch - Images Shape: {images.shape}, Labels Shape: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 1 - Batch 1: 2625 images\n",
      "Client 1 - Batch 2: 1000 images\n",
      "Client 1 - Batch 3: 1000 images\n",
      "Client 1 - Batch 4: 1000 images\n",
      "Client 1 - Batch 5: 1000 images\n",
      "Client 1 - Batch 6: 1000 images\n",
      "Client 1 - Batch 7: 1000 images\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import random_split, ConcatDataset\n",
    "\n",
    "# Split each client's 5625 images into 1 initial batch and 6 incremental batches\n",
    "initial_split_size = 2625  # First batch size\n",
    "num_incremental_batches = 6  # Number of incremental batches\n",
    "new_data_per_batch = 500  # New images per incremental batch\n",
    "replay_size = 500  # Replay size (previously seen data to include)\n",
    "\n",
    "# Iterate over all clients to create incremental splits\n",
    "client_splits_cl = []\n",
    "\n",
    "for client_idx, client_dataset in enumerate(client_splits):\n",
    "    # Initial split: 2625 images for the first batch, remaining for incremental batches\n",
    "    remaining_split_size = len(client_dataset) - initial_split_size  # Should be 3000\n",
    "    first_split, remaining_dataset = random_split(client_dataset, [initial_split_size, remaining_split_size])\n",
    "\n",
    "    # Split the remaining dataset into 6 incremental batches of 500 new images each\n",
    "    incremental_splits = random_split(remaining_dataset, [new_data_per_batch] * num_incremental_batches)\n",
    "    \n",
    "    # Store the initial split as the first batch\n",
    "    client_splits_for_cl = [first_split]\n",
    "    \n",
    "    # Create incremental batches with replay technique\n",
    "    for i in range(num_incremental_batches):\n",
    "        # Get the previous seen data from all earlier batches\n",
    "        previous_data = ConcatDataset(client_splits_for_cl)\n",
    "        \n",
    "        # Select 500 random previously seen images (for replay)\n",
    "        replay_data, _ = random_split(previous_data, [replay_size, len(previous_data) - replay_size])\n",
    "        \n",
    "        # Create the new batch with 500 new images and 500 replay images\n",
    "        new_batch = ConcatDataset([incremental_splits[i], replay_data])\n",
    "        \n",
    "        # Add this new batch to the client's splits\n",
    "        client_splits_for_cl.append(new_batch)\n",
    "    \n",
    "    client_splits_cl.append(client_splits_for_cl)\n",
    "\n",
    "# Verify the incremental splits for Client 1\n",
    "for i, split in enumerate(client_splits_cl[0]):\n",
    "    print(f\"Client 1 - Batch {i+1}: {len(split)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Function to create DataLoaders for each client\n",
    "def create_client_loaders(dataset, num_clients=8, batch_size=128, val_split=0.1, num_workers=8):\n",
    "    \"\"\"Split dataset into `num_clients` parts and create train/validation loaders.\"\"\"\n",
    "    client_loaders = []\n",
    "    val_loaders = []\n",
    "    \n",
    "    # Split the dataset randomly into `num_clients` equal parts\n",
    "    client_datasets = random_split(dataset, [len(dataset) // num_clients] * num_clients)\n",
    "    \n",
    "    for client_dataset in client_datasets:\n",
    "        # Further split each client's dataset into train and validation sets\n",
    "        train_size = int((1 - val_split) * len(client_dataset))\n",
    "        val_size = len(client_dataset) - train_size\n",
    "        train_dataset, val_dataset = random_split(client_dataset, [train_size, val_size])\n",
    "        \n",
    "        # Create DataLoaders for the client with pin_memory and optimizations\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                                  num_workers=num_workers, pin_memory=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                                num_workers=num_workers, pin_memory=True)\n",
    "        \n",
    "        client_loaders.append(train_loader)\n",
    "        val_loaders.append(val_loader)\n",
    "    \n",
    "    return client_loaders, val_loaders\n",
    "\n",
    "# Assuming `dataset_train` is your training dataset\n",
    "train_loaders, val_loaders = create_client_loaders(dataset_train, num_clients=8, batch_size=128, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model for Client 1 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_1_model.pth\n",
      "Loaded model for Client 2 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_2_model.pth\n",
      "Loaded model for Client 3 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_3_model.pth\n",
      "Loaded model for Client 4 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_4_model.pth\n",
      "Loaded model for Client 5 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_5_model.pth\n",
      "Loaded model for Client 6 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_6_model.pth\n",
      "Loaded model for Client 7 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_7_model.pth\n",
      "Loaded model for Client 8 from /raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/client_8_model.pth\n",
      "\n",
      "--- Federated Learning Round 1 ---\n",
      "\n",
      "Training client 1 with the global model\n",
      "Epoch 1/3, Train Accuracy: 1.08%\n",
      "Epoch 2/3, Train Accuracy: 1.08%\n",
      "Epoch 3/3, Train Accuracy: 1.08%\n",
      "\n",
      "Training client 2 with the global model\n",
      "Epoch 1/3, Train Accuracy: 0.96%\n",
      "Epoch 2/3, Train Accuracy: 0.96%\n",
      "Epoch 3/3, Train Accuracy: 0.96%\n",
      "\n",
      "Training client 3 with the global model\n",
      "Epoch 1/3, Train Accuracy: 1.07%\n",
      "Epoch 2/3, Train Accuracy: 1.07%\n",
      "Epoch 3/3, Train Accuracy: 1.07%\n",
      "\n",
      "Training client 4 with the global model\n",
      "Epoch 1/3, Train Accuracy: 0.73%\n",
      "Epoch 2/3, Train Accuracy: 0.73%\n",
      "Epoch 3/3, Train Accuracy: 0.73%\n",
      "\n",
      "Training client 5 with the global model\n",
      "Epoch 1/3, Train Accuracy: 1.01%\n",
      "Epoch 2/3, Train Accuracy: 1.01%\n",
      "Epoch 3/3, Train Accuracy: 1.01%\n",
      "\n",
      "Training client 6 with the global model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 166\u001b[0m\n\u001b[1;32m    163\u001b[0m train_loaders, val_loaders \u001b[38;5;241m=\u001b[39m create_client_loaders(dataset_train, num_clients\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# Apply FL and test the global model\u001b[39;00m\n\u001b[0;32m--> 166\u001b[0m global_model \u001b[38;5;241m=\u001b[39m \u001b[43mapply_federated_learning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcl_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 131\u001b[0m, in \u001b[0;36mapply_federated_learning\u001b[0;34m(cl_models, train_loaders, val_loaders, test_loader, num_clients, num_epochs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m client_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_clients):\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_idx\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with the global model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 131\u001b[0m     client_state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_client\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclient_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     client_state_dicts\u001b[38;5;241m.\u001b[39mappend(client_state_dict)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# Federated optimization after each round using FedOpt\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 96\u001b[0m, in \u001b[0;36mfine_tune_client\u001b[0;34m(global_model, train_loader, val_loader, num_epochs, use_mixed_precision)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_mixed_precision:\n\u001b[1;32m     95\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 96\u001b[0m     \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m     scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:416\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    414\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 416\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:314\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    315\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.cuda.amp import autocast, GradScaler  # For mixed-precision training\n",
    "\n",
    "# Path where client models are saved\n",
    "saved_models_dir = '/raid/home/somayeh.shami/project/somayeh_workspace/federated_learning/cl_models/'\n",
    "\n",
    "# Model Preparation (ResNet18 for CIFAR-100)\n",
    "def prepare_model(num_classes=100, use_dropout=False, dropout_prob=0.2):\n",
    "    \"\"\"Load a pre-trained Resnet18 model and modify it for CIFAR100 with optional dropout.\"\"\"\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    if use_dropout:\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "    else:\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model\n",
    "\n",
    "# Function to load a model from a file\n",
    "def load_client_model(client_idx, save_dir):\n",
    "    model = prepare_model().to(device)\n",
    "    model_path = os.path.join(save_dir, f'client_{client_idx}_model.pth')\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    print(f'Loaded model for Client {client_idx} from {model_path}')\n",
    "    return model\n",
    "\n",
    "# Initialize optimizer state variables for FedOpt (e.g., FedAdam)\n",
    "optimizer_state = None\n",
    "beta_1 = 0.9  # FedAdam specific hyperparameters\n",
    "beta_2 = 0.99\n",
    "epsilon = 1e-8\n",
    "eta = 0.001  # Learning rate for the server-side optimizer\n",
    "\n",
    "# Function for adaptive federated optimization (FedAdam)\n",
    "def federated_opt(state_dicts, global_model, optimizer_state):\n",
    "    global beta_1, beta_2, epsilon, eta\n",
    "\n",
    "    if optimizer_state is None:\n",
    "        optimizer_state = {key: torch.zeros_like(param) for key, param in global_model.state_dict().items()}\n",
    "\n",
    "    avg_state_dict = {}\n",
    "    \n",
    "    # Compute federated optimization using the FedAdam algorithm\n",
    "    for key in state_dicts[0].keys():\n",
    "        # Compute the difference between the clients' weights and the global model\n",
    "        delta_w = sum([state_dict[key] - global_model.state_dict()[key] for state_dict in state_dicts]) / len(state_dicts)\n",
    "        \n",
    "        # Update optimizer state with momentum and variance terms\n",
    "        optimizer_state[key] = beta_1 * optimizer_state[key] + (1 - beta_1) * delta_w\n",
    "        optimizer_variance = beta_2 * optimizer_state[key] + (1 - beta_2) * (delta_w ** 2)\n",
    "        \n",
    "        # Compute the bias-corrected update for FedAdam\n",
    "        m_hat = optimizer_state[key] / (1 - beta_1)\n",
    "        v_hat = optimizer_variance / (1 - beta_2)\n",
    "        \n",
    "        # Apply the FedAdam update rule\n",
    "        avg_state_dict[key] = global_model.state_dict()[key] - eta * m_hat / (torch.sqrt(v_hat) + epsilon)\n",
    "\n",
    "    return avg_state_dict, optimizer_state\n",
    "\n",
    "# Training function for each client after receiving the global model\n",
    "def fine_tune_client(global_model, train_loader, val_loader, num_epochs=3, use_mixed_precision=True):\n",
    "    model = global_model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    \n",
    "    # Optional: Mixed precision training\n",
    "    scaler = GradScaler() if use_mixed_precision else None\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if use_mixed_precision:\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            if use_mixed_precision:\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Accuracy: {train_accuracy:.2f}%')\n",
    "\n",
    "    return model.state_dict()\n",
    "\n",
    "# Step 6: Federated Learning (FL) after Continual Learning (CL)\n",
    "def apply_federated_learning(cl_models, train_loaders, val_loaders, test_loader, num_clients=8, num_epochs=3):\n",
    "    global global_model, optimizer_state\n",
    "\n",
    "    global_model = prepare_model().to(device)\n",
    "\n",
    "    # Collect state dicts from all clients after CL\n",
    "    state_dicts = [model.state_dict() for model in cl_models]\n",
    "\n",
    "    # Perform federated optimization using FedOpt (FedAdam)\n",
    "    avg_state_dict, optimizer_state = federated_opt(state_dicts, global_model, optimizer_state)\n",
    "    global_model.load_state_dict(avg_state_dict)\n",
    "\n",
    "    for round in range(num_epochs):\n",
    "        print(f'\\n--- Federated Learning Round {round + 1} ---')\n",
    "        client_state_dicts = []\n",
    "\n",
    "        for client_idx in range(num_clients):\n",
    "            print(f'\\nTraining client {client_idx + 1} with the global model')\n",
    "            client_state_dict = fine_tune_client(global_model, train_loaders[client_idx], val_loaders[client_idx], num_epochs=3)\n",
    "            client_state_dicts.append(client_state_dict)\n",
    "\n",
    "        # Federated optimization after each round using FedOpt\n",
    "        avg_state_dict, optimizer_state = federated_opt(client_state_dicts, global_model, optimizer_state)\n",
    "        global_model.load_state_dict(avg_state_dict)\n",
    "\n",
    "        test_accuracy = test_global_model(global_model, test_loader)\n",
    "        print(f'Test Accuracy after Round {round + 1}: {test_accuracy:.2f}%')\n",
    "\n",
    "    return global_model\n",
    "\n",
    "# Function to test the global model\n",
    "def test_global_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    return test_accuracy\n",
    "\n",
    "# Load models saved after CL\n",
    "cl_models = [load_client_model(client_idx, saved_models_dir) for client_idx in range(1, 9)]\n",
    "\n",
    "# Prepare DataLoader splits for each client with pin_memory=True and fewer workers\n",
    "train_loaders, val_loaders = create_client_loaders(dataset_train, num_clients=8, batch_size=128)\n",
    "\n",
    "# Apply FL and test the global model\n",
    "global_model = apply_federated_learning(cl_models, train_loaders, val_loaders, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
